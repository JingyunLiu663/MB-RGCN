{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5fdb22c-572a-4111-8eee-4c73e65f3053",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jingyunliu/opt/anaconda3/envs/tfv1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/jingyunliu/opt/anaconda3/envs/tfv1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/jingyunliu/opt/anaconda3/envs/tfv1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/jingyunliu/opt/anaconda3/envs/tfv1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/jingyunliu/opt/anaconda3/envs/tfv1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/jingyunliu/opt/anaconda3/envs/tfv1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/jingyunliu/opt/anaconda3/envs/tfv1/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/jingyunliu/opt/anaconda3/envs/tfv1/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/jingyunliu/opt/anaconda3/envs/tfv1/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/jingyunliu/opt/anaconda3/envs/tfv1/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/jingyunliu/opt/anaconda3/envs/tfv1/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/jingyunliu/opt/anaconda3/envs/tfv1/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import pickle\n",
    "import os\n",
    "import Utils.TimeLogger as logger\n",
    "from Utils.TimeLogger import log\n",
    "import Utils.NNLayers as NNs\n",
    "from Utils.NNLayers import FC, Regularize, Activate, Dropout, Bias, getParam, defineParam\n",
    "import tensorflow as tf\n",
    "from tensorflow.core.protobuf import config_pb2\n",
    "from Params import args\n",
    "from DataHandler import LoadData, negSamp, transpose, transToLsts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f258340d-1240-436a-a095-7572eb0f8b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_norm_adj_mat(self, R):\n",
    "    '''\n",
    "    Create normalized adjacency matrix.\n",
    "    :param R:\n",
    "        user-item adjacency matrix (scipy matrix)\n",
    "    :return:\n",
    "        scipy.sparse.csr_matrix: Normalized adjacency matrix.\n",
    "    '''\n",
    "    adj_mat = sp.dok_matrix(\n",
    "        (args.user + args.item, args.user + args.item), dtype=np.float32\n",
    "    )\n",
    "    adj_mat = adj_mat.tolil()\n",
    "    R = R.tolil()  # R is a user-item adjacency matrix\n",
    "\n",
    "    adj_mat[:args.user, args.user:] = R\n",
    "    adj_mat[args.user:, : args.user] = R.T\n",
    "    adj_mat = adj_mat.todok()\n",
    "    print(\"Already create adjacency matrix.\")\n",
    "\n",
    "    rowsum = np.array(adj_mat.sum(1))\n",
    "    d_inv = np.power(rowsum + 1e-9, -0.5).flatten()\n",
    "    d_inv[np.isinf(d_inv)] = 0.0\n",
    "    d_mat_inv = sp.diags(d_inv)\n",
    "    norm_adj_mat = d_mat_inv.dot(adj_mat)\n",
    "    norm_adj_mat = norm_adj_mat.dot(d_mat_inv)\n",
    "    print(\"Already normalize adjacency matrix.\")\n",
    "    return norm_adj_mat.tocsr()\n",
    "\n",
    "\n",
    "def _convert_sp_mat_to_sp_tensor(self, X):\n",
    "    \"\"\"\n",
    "    Convert a scipy sparse matrix to tf.SparseTensor.\n",
    "    :return: tf.SparseTensor: SparseTensor after conversion.\n",
    "    \"\"\"\n",
    "    coo = X.tocoo().astype(np.float32)\n",
    "    indices = np.mat([coo.row, coo.col]).transpose()\n",
    "    return tf.SparseTensor(indices, coo.data, coo.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2671fe77-d85f-4385-9156-fe7580b5d140",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_lightGCN_embed(self, ego_embedding, behavior_ind, n_layers=2):\n",
    "    #TODO: remember to set n_layers as a self.property!!!\n",
    "    all_embeddings = [ego_embedding]\n",
    "    A_hat = (self._convert_sp_mat_to_sp_tensor(self.create_norm_adj_mat(self.trnMats[behavior_ind])))\n",
    "    for k in range(0, n_layers):\n",
    "        ego_embedding = tf.sparse.sparse_dense_matmul(A_hat, ego_embedding)\n",
    "        all_embeddings.append(ego_embedding)\n",
    "    all_embeddings = tf.stack(all_embeddings, 1)\n",
    "    all_embeddings = tf.reduce_mean(\n",
    "        input_tensor=all_embeddings, axis=1, keepdims=False\n",
    "    )\n",
    "    return all_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f9dda37-35d9-42ca-b03d-852495825bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cascading_block(self):\n",
    "    # TODO: have a look at the variables not used\n",
    "    self.temlats = list()  # NOT used\n",
    "    self.translats = list() # NOT used\n",
    "    ulats = []\n",
    "    ilats = []\n",
    "    # ues a dictionary to store the embedding (user || item) for each behavior\n",
    "    all_embeddings = {}\n",
    "    # state the tf.Variables [mapping from input space to embedding space]\n",
    "    UEmbed = NNs.defineParam('UEmbed', shape=[args.user, args.latdim], dtype=tf.float32,\n",
    "                             reg=True)  # [user * latDim]\n",
    "    IEmbed = NNs.defineParam('IEmbed', shape=[args.item, args.latdim], dtype=tf.float32,\n",
    "                             reg=True)  # [item * latDim]\n",
    "    # Equation (1): concat the user embedding and item embedding\n",
    "    # [(user + item) * latDim]\n",
    "    total_embeddings = tf.concat([UEmbed, IEmbed], axis=0)\n",
    "    for inp in range(args.intTypes):\n",
    "        layer_embeddings = total_embeddings\n",
    "        # use LightGCN to embed the input\n",
    "        layer_embeddings = self._create_lightGCN_embed(layer_embeddings, inp)\n",
    "        # TODO: add dropout layer here?\n",
    "        # Embedding Normalization (L2 Norm)\n",
    "        layer_embeddings = layer_embeddings / (1e-6 + tf.sqrt(1e-6 + tf.reduce_sum(tf.square(layer_embeddings),\n",
    "                                                                                   axis=-1, keepdims=True)))\n",
    "        # Residual\n",
    "        total_embeddings = layer_embeddings + total_embeddings\n",
    "        all_embeddings[inp] = total_embeddings\n",
    "        # TODO: data redundancy? the user embedding & item embedding matrix as 2 lists <=> all_embeddings[inp] as a dict\n",
    "        ulat, ilat = tf.split(\n",
    "            all_embeddings[inp], [args.user, args.item], 0\n",
    "        )\n",
    "        ulats.append(ulat)\n",
    "        ilats.append(ilat)\n",
    "    # use the latest [-1] users/items embedding for look-up\n",
    "    # ulat = FC(ulat[-1], args.latdim, reg=True, useBias=True, name='ablation_trans',\n",
    "    # \t\t  activation='relu')\n",
    "    # ilat = FC(ilats[-1], args.latdim, reg=True, useBias=True, name='ablation_trans', reuse=True,\n",
    "    # \t\t  activation='relu')\n",
    "    pckUlat = tf.nn.embedding_lookup(ulats[-1], self.uids)\n",
    "    pckIlat = tf.nn.embedding_lookup(ilats[-1], self.iids)\n",
    "    predLat = pckUlat * pckIlat * args.mult\n",
    "    for i in range(1):\n",
    "        predLat = FC(predLat, args.latdim, reg=True, useBias=True, activation='relu') + predLat\n",
    "    pred = tf.squeeze(FC(predLat, 1, reg=True, useBias=True)) # * args.mult\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc578ebd-2c14-4564-8961-3370bb9e7dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = 10\n",
    "item = 8\n",
    "latdim = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b1a760f5-75e9-46de-97ec-9b9a5cf82c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "UEmbed = tf.random.uniform([user, latdim])\n",
    "IEmbed = tf.random.uniform([item, latdim])\n",
    "\n",
    "A_hat = tf.sparse.SparseTensor()\n",
    "A_hat = tf.random.uniform([item + user, item + user])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fdf51c34-d95d-48d0-bc7f-339851aac854",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_op = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e84392e2-0447-42a8-a727-068fdbbffdf0",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Input must be a SparseTensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-79b8ff790003>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtotal_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUEmbed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIEmbed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mall_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtotal_embeddings\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtotal_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_dense_matmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tfv1/lib/python3.6/site-packages/tensorflow/python/ops/sparse_ops.py\u001b[0m in \u001b[0;36msparse_tensor_dense_matmul\u001b[0;34m(sp_a, b, adjoint_a, adjoint_b, name)\u001b[0m\n\u001b[1;32m   2352\u001b[0m   \"\"\"\n\u001b[1;32m   2353\u001b[0m   \u001b[0;31m# pylint: enable=line-too-long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2354\u001b[0;31m   \u001b[0msp_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_to_sparse_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msp_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2355\u001b[0m   with ops.name_scope(name, \"SparseTensorDenseMatMul\",\n\u001b[1;32m   2356\u001b[0m                       [sp_a.indices, sp_a.values, b]) as name:\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tfv1/lib/python3.6/site-packages/tensorflow/python/ops/sparse_ops.py\u001b[0m in \u001b[0;36m_convert_to_sparse_tensor\u001b[0;34m(sp_input)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msp_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msp_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input must be a SparseTensor.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msp_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Input must be a SparseTensor."
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init_op) #execute init_op\n",
    "    #print the random values that we sample\n",
    "    total_embeddings = tf.concat([UEmbed, IEmbed], axis=0)\n",
    "    all_embeddings = [total_embeddings]\n",
    "    total_embeddings = tf.sparse.sparse_dense_matmul(A_hat, total_embeddings)\n",
    "    print(total_embeddings.shape)\n",
    "    print(sess.run(total_embeddings))\n",
    "    print(all_embeddings[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ecf1f5-9fee-45ba-beb9-03c67a5d5893",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_v1.14.0",
   "language": "python",
   "name": "tfv1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
